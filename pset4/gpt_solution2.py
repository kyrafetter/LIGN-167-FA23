'''
LIGN 167 PSET 4
Kyra Fetter, A16819058
Lina Battikha, A16852105
Oishani Bandopadhyay, A16800427

Group Member Contributions:
Kyra: 9, 10, 11
Lina: 1, 2, 3, 4
Oishani: 5, 6, 7, 8 
Everyone: Reviewing code and debugging
'''

# Problem 1 - Lina


# Problem 2 - Lina


# Problem 3 - Lina


# Problem 4 - Lina


# Problem 5 - Oishani


# Problem 6 - Oishani


# Problem 7 - Oishani


# Problem 8 - Oishani


# Problem 9 - Kyra
'''
Link: https://chat.openai.com/share/751ea31a-21ca-446f-bccc-6e851fb603e9
GPT-4 stood by its first response and did not provide any significant changes.
This new response remains correct.

Let's review the response and identify the error.

Upon revisiting the explanation, I see that the description of the loss and its
implications for the probability distribution learned by the model was accurate.
The loss is indeed decreasing over time, which suggests the RNN is learning to
better predict the next word in a sequence based on the context provided by the
preceding words.

However, I should clarify the relationship between the loss and the probability
distribution: a decreasing loss over training epochs implies that the RNN's
estimated probability distribution over sequences is increasingly aligning with
the true distribution of the training data. The model is not just becoming more
confident, but more importantly, it is becoming more correct in its predictions.

The error may not lie in the conceptual explanation but could be a misunderstanding
of expectations. If the error is expected to be in the code description, please
provide more information, and I'll address it accordingly. If the error is expected
to be in the interpretation of the training output, then the explanation above
stands correct: a decreasing loss is typically a sign of a model learning and
improving its performance on the training data.
'''


# Problem 10 - Kyra


# Problem 11 - Kyra

